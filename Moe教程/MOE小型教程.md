
---

# ğŸ“˜ Mixture of Experts (MoE) è¯¦è§£æ•™ç¨‹  
> **ä»æ•°å­¦ç›´è§‰ â†’ ç¨ å¯†å®ç° â†’ ç¨€ç–å®ç° â†’ ä»£ç é€è¡Œè§£æ**

---

## ä¸€ã€MoE æ˜¯ä»€ä¹ˆï¼Ÿä¸ºä»€ä¹ˆéœ€è¦å®ƒï¼Ÿ

### 1.1 æ ¸å¿ƒæ€æƒ³
- **â€œåˆ†è€Œæ²»ä¹‹â€**ï¼šä¸åŒè¾“å…¥ç”±ä¸åŒçš„å­ç½‘ç»œï¼ˆâ€œä¸“å®¶â€ï¼‰å¤„ç†ã€‚
- **åŠ¨æ€è·¯ç”±**ï¼šä¸€ä¸ªâ€œé—¨æ§ç½‘ç»œâ€ï¼ˆgateï¼‰å†³å®šæ¯ä¸ªè¾“å…¥åº”ä¿¡ä»»å“ªäº›ä¸“å®¶ã€‚
- **åŠ æƒèåˆ**ï¼šæœ€ç»ˆè¾“å‡ºæ˜¯è¢«é€‰ä¸­ä¸“å®¶è¾“å‡ºçš„åŠ æƒå’Œã€‚

### 1.2 ä¼˜åŠ¿
- **é«˜å®¹é‡**ï¼šæ€»å‚æ•°é‡ = æ‰€æœ‰ä¸“å®¶å‚æ•°ä¹‹å’Œï¼ˆå¯æå¤§ï¼‰
- **ä½è®¡ç®—æˆæœ¬**ï¼šæ¯æ¬¡åªæ¿€æ´»éƒ¨åˆ†ä¸“å®¶ï¼ˆç¨€ç– MoEï¼‰
- **ä¸“ä¸šåŒ–**ï¼šä¸“å®¶å¯è‡ªåŠ¨å­¦ä¹ å¤„ç†ä¸åŒç±»å‹çš„æ•°æ®ï¼ˆå¦‚ä»£ç ã€æ•°å­¦ã€æ–‡æœ¬ï¼‰

> âœ… **å…¸å‹åº”ç”¨**ï¼šMixtral 8x7Bï¼ˆ47B å‚æ•°ï¼Œä½†æ¯ token åªç”¨ ~12Bï¼‰

---

## äºŒã€MoE çš„æ•°å­¦å½¢å¼

ç»™å®šè¾“å…¥å‘é‡ $ x \in \mathbb{R}^d $ï¼ŒMoE è¾“å‡ºä¸ºï¼š

$$
y = \sum_{i=1}^{E} w_i(x) \cdot f_i(x)
$$

å…¶ä¸­ï¼š
- $ E $ï¼šä¸“å®¶æ€»æ•°
- $ f_i(x) \in \mathbb{R}^o $ï¼šç¬¬ $ i $ ä¸ªä¸“å®¶çš„è¾“å‡ºï¼ˆä¸€ä¸ªç¥ç»ç½‘ç»œï¼‰
- $ w_i(x) \in [0,1] $ï¼šé—¨æ§ç½‘ç»œç»™å‡ºçš„æƒé‡ï¼Œä¸” $ \sum_i w_i(x) = 1 $

> ğŸ” **å…³é”®**ï¼šæƒé‡ $ w_i(x) $ æ˜¯**è¾“å…¥ç›¸å…³çš„**ï¼Œå³æ¨¡å‹èƒ½â€œè‡ªé€‚åº”é€‰æ‹©ä¸“å®¶â€ã€‚

---

## ä¸‰ã€ç¨ å¯† MoEï¼ˆDense MoEï¼‰å®ç°

### 3.1 è®¾è®¡æ€è·¯
- **æ‰€æœ‰ä¸“å®¶éƒ½å‚ä¸æ¯ä¸ªè¾“å…¥çš„è®¡ç®—**
- æƒé‡ç”± softmax å½’ä¸€åŒ–
- ä½¿ç”¨ `torch.bmm` é«˜æ•ˆå®ŒæˆåŠ æƒæ±‚å’Œ

### 3.2 å®Œæ•´ä»£ç  + é€è¡Œè¯¦è§£

```python
import torch
import torch.nn as nn
import torch.nn.functional as F

# å°è£…çº¿æ€§å±‚ï¼ˆä»…ä¸ºæ¸…æ™°ï¼Œå®é™…å¯ç›´æ¥ç”¨ nn.Linearï¼‰
class Linear(nn.Module):
    def __init__(self, in_features, out_features):
        super().__init__()
        self.fc = nn.Linear(in_features, out_features)  # æ ‡å‡†å…¨è¿æ¥å±‚
    
    def forward(self, x):
        return self.fc(x)

class DenseMoELayer(nn.Module):
    def __init__(self, num_experts, in_features, out_features):
        super().__init__()
        # åˆ›å»º num_experts ä¸ªç‹¬ç«‹ä¸“å®¶ï¼Œæ¯ä¸ªéƒ½æ˜¯ Linear(in â†’ out)
        self.experts = nn.ModuleList([
            Linear(in_features, out_features) for _ in range(num_experts)
        ])
        # é—¨æ§ç½‘ç»œï¼šè¾“å…¥ x â†’ è¾“å‡º E ä¸ª logitsï¼ˆæœªå½’ä¸€åŒ–çš„ä¸“å®¶åˆ†æ•°ï¼‰
        self.gate = nn.Linear(in_features, num_experts)

    def forward(self, x):
        """
        è¾“å…¥: x.shape = [batch_size, in_features]
        è¾“å‡º: y.shape = [batch_size, out_features]
        """
        # Step 1: é—¨æ§æ‰“åˆ† + softmax å½’ä¸€åŒ–
        gate_logits = self.gate(x)                     # [B, E]
        gate_score = F.softmax(gate_logits, dim=-1)    # [B, E]ï¼Œæ¯è¡Œå’Œä¸º1

        # Step 2: æ‰€æœ‰ä¸“å®¶å¹¶è¡Œè®¡ç®—è¾“å‡º
        # å¯¹æ¯ä¸ªä¸“å®¶ eï¼Œè®¡ç®— e(x) â†’ [B, out]
        # ç”¨ torch.stack åœ¨ dim=1 å †å  â†’ [B, E, out]
        expert_outputs = torch.stack([
            expert(x) for expert in self.experts
        ], dim=1)  # shape: [batch_size, num_experts, out_features]

        # Step 3: åŠ æƒèåˆ
        # gate_score.unsqueeze(1): [B, 1, E]
        # expert_outputs:           [B, E, out]
        # torch.bmm: batch matrix multiplication
        # ç»“æœ: [B, 1, out] â†’ squeeze(1) â†’ [B, out]
        output = torch.bmm(
            gate_score.unsqueeze(1),   # [B, 1, E]
            expert_outputs             # [B, E, out]
        ).squeeze(1)  # [B, out]

        return output
```

### 3.3 å…³é”®ç‚¹è§£æ

#### â“ ä¸ºä»€ä¹ˆç”¨ `torch.stack(..., dim=1)`ï¼Ÿ
- æˆ‘ä»¬å¸Œæœ›å¾—åˆ°å½¢çŠ¶ `[B, E, out]`ï¼Œå…¶ä¸­ï¼š
  - ç¬¬ 0 ç»´ï¼šbatch
  - ç¬¬ 1 ç»´ï¼šä¸“å®¶ç´¢å¼•
  - ç¬¬ 2 ç»´ï¼šè¾“å‡ºç‰¹å¾
- `dim=1` è¡¨ç¤ºåœ¨â€œä¸“å®¶ç»´åº¦â€ä¸Šå †å ã€‚

#### â“ ä¸ºä»€ä¹ˆç”¨ `torch.bmm`ï¼Ÿ
- æ•°å­¦ä¸Šï¼š$ y_b = \sum_e w_{b,e} \cdot f_e(x_b) $
- çŸ©é˜µå½¢å¼ï¼š$ y_b = w_b^\top \cdot F_b $ï¼Œå…¶ä¸­ $ F_b \in \mathbb{R}^{E \times o} $
- `bmm` æ­£å¥½å®ç° batch-wise çš„è¿™ç§ä¹˜æ³•ã€‚

#### âš ï¸ ç¼ºç‚¹
- **è®¡ç®—æ‰€æœ‰ä¸“å®¶**ï¼Œå³ä½¿æŸäº›æƒé‡æ¥è¿‘ 0 â†’ æµªè´¹ç®—åŠ›
- æ— æ³•æ‰©å±•åˆ°å¤§ $ E $ï¼ˆå¦‚ 1000+ ä¸“å®¶ï¼‰

---

## å››ã€ç¨€ç– MoEï¼ˆSparse MoEï¼‰å®ç°

### 4.1 è®¾è®¡ç›®æ ‡
- æ¯ä¸ªè¾“å…¥åªæ¿€æ´» **top-k ä¸“å®¶**ï¼ˆå¦‚ k=2ï¼‰
- å…¶ä»–ä¸“å®¶**ä¸è´¡çŒ®æ¢¯åº¦**ï¼ˆè®­ç»ƒç¨€ç–ï¼‰
- ä¿æŒä»£ç ç®€æ´ï¼ˆæ•™å­¦å‹å¥½ï¼‰

### 4.2 å®Œæ•´ä»£ç  + é€è¡Œæ·±åº¦è§£æ

```python
class SparseMoELayer(nn.Module):
    def __init__(self, num_experts, in_features, out_features, top_k=2):
        super().__init__()
        self.num_experts = num_experts
        self.top_k = top_k
        # åˆ›å»ºä¸“å®¶åˆ—è¡¨ï¼ˆæ¯ä¸ªä¸“å®¶ç‹¬ç«‹ï¼‰
        self.experts = nn.ModuleList([
            Linear(in_features, out_features) for _ in range(num_experts)
        ])
        # é—¨æ§ç½‘ç»œï¼šè¾“å…¥ â†’ E ä¸ª logits
        self.gate = nn.Linear(in_features, num_experts)

    def forward(self, x):
        """
        æ”¯æŒä¸¤ç§è¾“å…¥å½¢çŠ¶:
          - [B, D]         â†’ å•æ­¥æ¨ç†
          - [B, L, D]      â†’ åºåˆ—è¾“å…¥ï¼ˆå¦‚ Transformerï¼‰
        """
        # è®°å½•åŸå§‹å½¢çŠ¶ï¼ˆç”¨äºæœ€åæ¢å¤ï¼‰
        original_shape = x.shape
        # å±•å¹³æ‰€æœ‰éç‰¹å¾ç»´åº¦ï¼š[B, L, D] â†’ [B*L, D]
        x_flat = x.view(-1, x.size(-1))  # [N, D], N = total tokens

        # Step 1: é—¨æ§æ‰“åˆ†ï¼ˆlogitsï¼‰
        gate_logits = self.gate(x_flat)  # [N, E]

        # Step 2: é€‰æ‹© top-k ä¸“å®¶
        # topk_vals: top-k çš„ logits å€¼      â†’ [N, k]
        # topk_idxs: top-k çš„ä¸“å®¶ç´¢å¼•       â†’ [N, k]
        topk_vals, topk_idxs = torch.topk(gate_logits, self.top_k, dim=-1)
        # å¯¹ top-k logits åš softmaxï¼ˆä»…åœ¨è¿™ k ä¸ªä¸Šå½’ä¸€åŒ–ï¼‰
        topk_weights = F.softmax(topk_vals, dim=-1)  # [N, k]

        # Step 3: åˆå§‹åŒ–è¾“å‡ºå¼ é‡
        # å½¢çŠ¶: [N, out_features]ï¼Œå…¨ 0
        # æ³¨æ„ï¼šè¿™é‡Œç›´æ¥ä½¿ç”¨ out_featuresï¼Œé¿å…ä¾èµ– x_flat çš„åˆ—æ•°
        output_flat = torch.zeros(
            x_flat.size(0), self.experts[0].fc.out_features,
            device=x.device, dtype=x.dtype
        )  # [N, out]

        # Step 4: ã€æ ¸å¿ƒã€‘éå†æ¯ä¸ªä¸“å®¶ï¼Œç´¯åŠ å…¶è¢«é€‰ä¸­æ—¶çš„è´¡çŒ®
        for i, expert in enumerate(self.experts):
            # (a) æ‰¾å‡ºå“ªäº› token é€‰æ‹©äº†å½“å‰ä¸“å®¶ i
            # topk_idxs == i â†’ [N, k] çš„ bool å¼ é‡
            # True è¡¨ç¤ºè¯¥ token åœ¨ top-k çš„æŸä¸ªä½ç½®é€‰æ‹©äº†ä¸“å®¶ i
            selected = (topk_idxs == i)  # [N, k]

            # (b) å¦‚æœæ²¡æœ‰ä»»ä½• token é€‰æ‹©æ­¤ä¸“å®¶ï¼Œè·³è¿‡
            if not selected.any():
                continue

            # (c) æå–æ¯ä¸ª token åˆ†é…ç»™ä¸“å®¶ i çš„æ€»æƒé‡
            # torch.where(condition, x, y): condition ä¸º True å– xï¼Œå¦åˆ™å– y
            # â†’ å°†æœªé€‰ä¸­çš„ä½ç½®ç½® 0ï¼Œé€‰ä¸­çš„ä¿ç•™æƒé‡
            # â†’ ç„¶åå¯¹ k ä¸ªä½ç½®æ±‚å’Œï¼Œå¾—åˆ°æ¯ä¸ª token å¯¹ä¸“å®¶ i çš„æ€»æƒé‡
            weights = torch.where(selected, topk_weights, 0.0).sum(dim=-1)  # [N]

            # (d) è®¡ç®—å½“å‰ä¸“å®¶å¯¹æ‰€æœ‰ token çš„è¾“å‡º
            # æ³¨æ„ï¼šè¿™é‡Œè®¡ç®—äº†æ‰€æœ‰ tokenï¼ŒåŒ…æ‹¬æœªé€‰ä¸­çš„ï¼ˆä½†åç»­ä¼šä¹˜ 0ï¼‰
            expert_out = expert(x_flat)  # [N, out]

            # (e) åŠ æƒç´¯åŠ åˆ°æ€»è¾“å‡º
            # weights: [N] â†’ unsqueeze(-1) â†’ [N, 1]
            # expert_out: [N, out]
            # å¹¿æ’­ç›¸ä¹˜: [N, 1] * [N, out] â†’ [N, out]
            output_flat += weights.unsqueeze(-1) * expert_out

        # Step 5: æ¢å¤åŸå§‹å½¢çŠ¶
        # ä¾‹å¦‚: [N, out] â†’ [B, L, out]
        output = output_flat.view(*original_shape[:-1], -1)
        return output
```

---

### 4.3 å›åº”ä½ çš„æ ¸å¿ƒç–‘é—®

#### â“ ä¸ºä»€ä¹ˆ `expert_out` æ²¡æœ‰ä¸“å®¶ç»´åº¦ï¼Ÿ

> **å› ä¸ºè¿™ä¸ªå®ç°é‡‡ç”¨â€œé€ä¸“å®¶ç´¯åŠ â€ç­–ç•¥ï¼Œè€Œéâ€œä¸€æ¬¡æ€§å †å æ‰€æœ‰ä¸“å®¶â€ã€‚**

- åœ¨ç¨ å¯† MoE ä¸­ï¼Œæˆ‘ä»¬æ„é€ äº† `[B, E, out]` å¼ é‡ï¼Œç„¶åä¸€æ¬¡æ€§åŠ æƒã€‚
- åœ¨ç¨€ç– MoE ä¸­ï¼Œæˆ‘ä»¬**å¾ªç¯éå†æ¯ä¸ªä¸“å®¶**ï¼š
  - å¯¹ä¸“å®¶ `i`ï¼Œè®¡ç®—å®ƒå¯¹**æ‰€æœ‰ token** çš„è¾“å‡º â†’ `[N, out]`
  - ä½†åªä¿ç•™**è¢«é€‰ä¸­çš„ token** çš„è´¡çŒ®ï¼ˆé€šè¿‡ `weights` æ©ç ï¼‰
  - ç´¯åŠ åˆ° `output_flat`

âœ… **ä¼˜ç‚¹**ï¼š
- é€»è¾‘æ¸…æ™°ï¼Œæ˜“äºç†è§£
- è‡ªç„¶æ”¯æŒç¨€ç–æ€§ï¼ˆæœªè¢«é€‰ä¸“å®¶æ¢¯åº¦ä¸º 0ï¼‰

âš ï¸ **æ³¨æ„**ï¼šå½“å‰å®ç°ä»è®¡ç®—äº†æ‰€æœ‰ä¸“å®¶çš„å‰å‘ï¼ˆä¸ºäº†ç®€å•ï¼‰ï¼Œä½†**æ¢¯åº¦åªæ›´æ–°è¢«é€‰ä¸­çš„ä¸“å®¶**ï¼ˆå› ä¸ºæœªè¢«é€‰ä¸­çš„ `weights=0`ï¼‰ã€‚

> ğŸ’¡ **çœŸæ­£é«˜æ•ˆçš„åšæ³•**ï¼šåªè®¡ç®—è¢«é€‰ä¸­çš„ä¸“å®¶ï¼ˆéœ€å¤æ‚ç´¢å¼•ï¼‰ï¼Œä½†æœ¬å®ç°ä¼˜å…ˆä¿è¯å¯è¯»æ€§ã€‚

#### â“ `weights.unsqueeze(-1) * expert_out` å¦‚ä½•å·¥ä½œï¼Ÿ

- `weights`: `[N]` â†’ æ¯ä¸ª token å¯¹å½“å‰ä¸“å®¶çš„ä¿¡ä»»åº¦
- `weights.unsqueeze(-1)`: `[N, 1]`
- `expert_out`: `[N, out]`
- **å¹¿æ’­æœºåˆ¶**ï¼š`[N, 1] * [N, out] â†’ [N, out]`
  - æ¯ä¸ª token çš„è¾“å‡ºè¢«å…¶å¯¹åº”æƒé‡ç¼©æ”¾
  - æœªè¢«é€‰ä¸­çš„ token æƒé‡ä¸º 0 â†’ è´¡çŒ®ä¸º 0

---

## äº”ã€å¦‚ä½•è®­ç»ƒ MoEï¼Ÿ

### 5.1 åŸºæœ¬è®­ç»ƒæµç¨‹
```python
model = SparseMoELayer(4, 5, 3, top_k=2)
optimizer = torch.optim.Adam(model.parameters())
loss_fn = nn.CrossEntropyLoss()

for x, y in dataloader:
    logits = model(x)               # [B, 3]
    loss = loss_fn(logits, y)       # æ ‡å‡†åˆ†ç±»æŸå¤±
    loss.backward()
    optimizer.step()
```

### 5.2 é˜²æ­¢ä¸“å®¶åå¡Œï¼šè´Ÿè½½å‡è¡¡æŸå¤±ï¼ˆAuxiliary Lossï¼‰

```python
def moe_load_balance_loss(gate_logits, topk_idxs, num_experts):
    # è®¡ç®—æ¯ä¸ªä¸“å®¶è¢«é€‰ä¸­çš„é¢‘ç‡ï¼ˆè¿‘ä¼¼ï¼‰
    N = gate_logits.size(0)
    importance = torch.zeros(num_experts, device=gate_logits.device)
    importance.scatter_add_(0, topk_idxs.view(-1), torch.ones_like(topk_idxs.view(-1)).float())
    # ç†æƒ³é¢‘ç‡ = N * top_k / num_experts
    ideal_importance = torch.full_like(importance, N * topk_idxs.size(1) / num_experts)
    # è´Ÿè½½å‡è¡¡æŸå¤± = (å®é™… - ç†æƒ³)^2
    lb_loss = torch.mean((importance - ideal_importance) ** 2)
    return lb_loss

# è®­ç»ƒæ—¶
total_loss = ce_loss + 0.01 * lb_loss
```

---

## å…­ã€æ€»ç»“å¯¹æ¯”

| ç‰¹æ€§ | ç¨ å¯† MoE | ç¨€ç– MoEï¼ˆæœ¬å®ç°ï¼‰ |
|------|--------|------------------|
| **ä¸“å®¶æ¿€æ´»** | æ‰€æœ‰ | top-k |
| **è®¡ç®—æ•ˆç‡** | ä½ | ä¸­ï¼ˆå¯ä¼˜åŒ–ä¸ºé«˜ï¼‰ |
| **ä»£ç å¤æ‚åº¦** | ä½ | ä¸­ |
| **é€‚ç”¨åœºæ™¯** | æ•™å­¦ã€å°æ¨¡å‹ | å®éªŒã€ä¸­å°è§„æ¨¡ç¨€ç–æ¨¡å‹ |
| **æ˜¯å¦çœŸæ­£ç¨€ç–** | å¦ | **è®­ç»ƒæ—¶æ˜¯**ï¼ˆæ¢¯åº¦ç¨€ç–ï¼‰ |

---

## ä¸ƒã€ä¸‹ä¸€æ­¥å»ºè®®

1. **å¯è§†åŒ–ä¸“å®¶åˆ†å·¥**ï¼šè®°å½• `topk_idxs`ï¼Œåˆ†æå“ªäº›è¾“å…¥æ¿€æ´»å“ªäº›ä¸“å®¶
2. **å®ç°çœŸæ­£ç¨€ç–**ï¼šåªè®¡ç®—è¢«é€‰ä¸­çš„ä¸“å®¶ï¼ˆä½¿ç”¨ `torch.gather`ï¼‰
3. **åµŒå…¥ Transformer**ï¼šæ›¿æ¢ FFN å±‚ä¸º MoE å±‚
4. **å°è¯• MoE + LoRA å¾®è°ƒ**

