{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixture of Experts (MoE) æ¼”ç¤º\n",
    "\n",
    "æœ¬ Notebook æ¼”ç¤ºä¸€ä¸ªç®€å•çš„ **ç¨ å¯† MoEï¼ˆDense Mixture of Expertsï¼‰** å±‚çš„å®ç°ä¸å‰å‘ä¼ æ’­æµ‹è¯•ã€‚\n",
    "\n",
    "- æ¯ä¸ªä¸“å®¶æ˜¯ä¸€ä¸ªçº¿æ€§å±‚\n",
    "- é—¨æ§ç½‘ç»œå†³å®šæ¯ä¸ªè¾“å…¥å¯¹å„ä¸“å®¶çš„æƒé‡\n",
    "- è¾“å‡ºæ˜¯ä¸“å®¶è¾“å‡ºçš„åŠ æƒå’Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(Linear, self).__init__()\n",
    "        self.fc = nn.Linear(in_features, out_features)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoELayer(nn.Module):\n",
    "    def __init__(self, num_experts, in_features, out_features):\n",
    "        super(MoELayer, self).__init__()\n",
    "        self.num_experts = num_experts\n",
    "        # åˆ›å»ºå¤šä¸ªç‹¬ç«‹ä¸“å®¶\n",
    "        self.experts = nn.ModuleList([\n",
    "            Linear(in_features, out_features) for _ in range(num_experts)\n",
    "        ])\n",
    "        # é—¨æ§ç½‘ç»œï¼šè¾“å…¥ -> ä¸“å®¶ logits\n",
    "        self.gate = nn.Linear(in_features, num_experts)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x.shape: [batch_size, in_features]\n",
    "        \n",
    "        # 1. é—¨æ§æ‰“åˆ† + softmax å½’ä¸€åŒ–\n",
    "        gate_logits = self.gate(x)  # [B, E]\n",
    "        gate_score = F.softmax(gate_logits, dim=-1)  # [B, E]\n",
    "        \n",
    "        # 2. æ‰€æœ‰ä¸“å®¶å¹¶è¡Œè®¡ç®—è¾“å‡º\n",
    "        expert_outputs = torch.stack([\n",
    "            expert(x) for expert in self.experts\n",
    "        ], dim=1)  # [B, E, out_features]\n",
    "        \n",
    "        # 3. åŠ æƒèåˆï¼šbatch matrix multiplication\n",
    "        output = torch.bmm(\n",
    "            gate_score.unsqueeze(1),   # [B, 1, E]\n",
    "            expert_outputs             # [B, E, O]\n",
    "        ).squeeze(1)  # [B, O]\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¶…å‚æ•°è®¾ç½®\n",
    "input_size = 5\n",
    "output_size = 3\n",
    "num_experts = 4\n",
    "batch_size = 10\n",
    "\n",
    "# åˆ›å»ºæ¨¡å‹\n",
    "model = MoELayer(num_experts, input_size, output_size)\n",
    "\n",
    "# éšæœºè¾“å…¥\n",
    "demo = torch.randn(batch_size, input_size)\n",
    "\n",
    "# å‰å‘ä¼ æ’­\n",
    "output = model(demo)\n",
    "\n",
    "print(\"âœ… è¾“å…¥å½¢çŠ¶:\", demo.shape)\n",
    "print(\"âœ… è¾“å‡ºå½¢çŠ¶:\", output.shape)\n",
    "assert output.shape == (batch_size, output_size), \"è¾“å‡ºå½¢çŠ¶ä¸åŒ¹é…ï¼\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–é—¨æ§æƒé‡ï¼ˆå¸®åŠ©ç†è§£ä¸“å®¶é€‰æ‹©ï¼‰\n",
    "with torch.no_grad():\n",
    "    gate_logits = model.gate(demo)\n",
    "    gate_probs = F.softmax(gate_logits, dim=-1)\n",
    "    \n",
    "    print(\"ğŸ” ç¬¬ä¸€ä¸ªæ ·æœ¬çš„ä¸“å®¶æƒé‡åˆ†å¸ƒ:\")\n",
    "    for i, prob in enumerate(gate_probs[0]):\n",
    "        print(f\"  ä¸“å®¶ {i}: {prob:.4f}\")\n",
    "    \n",
    "    print(f\"\\nâœ… æƒé‡å’Œï¼ˆåº”ä¸º 1.0ï¼‰: {gate_probs[0].sum().item():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ä¸‹ä¸€æ­¥å»ºè®®\n",
    "\n",
    "- å°†æ­¤ MoE å±‚åµŒå…¥åˆ°å®Œæ•´æ¨¡å‹ä¸­è¿›è¡Œè®­ç»ƒï¼ˆå¦‚åˆ†ç±»ä»»åŠ¡ï¼‰\n",
    "- å°è¯•å®ç° **ç¨€ç– MoEï¼ˆtop-k gatingï¼‰**\n",
    "- æ·»åŠ  **è´Ÿè½½å‡è¡¡è¾…åŠ©æŸå¤±** é˜²æ­¢ä¸“å®¶åå¡Œ\n",
    "\n",
    "æ¬¢è¿ç»§ç»­æ¢ç´¢ï¼"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}